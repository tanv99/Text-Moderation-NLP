{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model Pipeline Testing",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXTMieIS37U3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3422df65-1516-417b-d22c-94c2df50c61e"
      },
      "source": [
        "%cd '/content/drive/My Drive/Toxic Content Detection'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Toxic Content Detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3l2dPwI7HRu"
      },
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "def preprocess(text):\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    tokens = re.split('\\W+', text)\n",
        "    text = \" \".join(tokens).strip().lower()\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjcIjxBs655o"
      },
      "source": [
        "!pip3 install --quiet sentencepiece\n",
        "import sentencepiece as spm\n",
        "from absl import logging\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "def use_lite_embed():\n",
        "    module = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder-lite/2\")\n",
        "    input_placeholder = tf.sparse_placeholder(tf.int64, shape=[None, None])\n",
        "    encodings = module(\n",
        "        inputs=dict(\n",
        "            values=input_placeholder.values,\n",
        "            indices=input_placeholder.indices,\n",
        "            dense_shape=input_placeholder.dense_shape))\n",
        "    \n",
        "    with tf.Session() as sess:\n",
        "        spm_path = sess.run(module(signature=\"spm_path\"))\n",
        "    sp = spm.SentencePieceProcessor()\n",
        "    sp.Load(spm_path)\n",
        "\n",
        "    def process_to_IDs_in_sparse_format(sp, sentences):\n",
        "        ids = [sp.EncodeAsIds(x) for x in sentences]\n",
        "        max_len = max(len(x) for x in ids)\n",
        "        dense_shape=(len(ids), max_len)\n",
        "        values=[item for sublist in ids for item in sublist]\n",
        "        indices=[[row,col] for row in range(len(ids)) for col in range(len(ids[row]))]\n",
        "        return (values, indices, dense_shape)\n",
        "\n",
        "    def embed(msgs):\n",
        "        values, indices, dense_shape = process_to_IDs_in_sparse_format(sp, msgs)\n",
        "        logging.set_verbosity(logging.ERROR)\n",
        "\n",
        "        with tf.Session() as session:\n",
        "            session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "            return session.run(\n",
        "                encodings,\n",
        "                feed_dict={input_placeholder.values: values,\n",
        "                            input_placeholder.indices: indices,\n",
        "                            input_placeholder.dense_shape: dense_shape})\n",
        "    return embed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6uBv1Dh5u1S"
      },
      "source": [
        "import pickle\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "def load_model():\n",
        "    model_path = \"Models/Embed+SKLearn/Original/USEL-Voting.model\"\n",
        "    with open(model_path, 'rb') as model_file:\n",
        "        model = pickle.load(model_file)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lpptt6Xx8lZE"
      },
      "source": [
        "def make_pipeline(preprocess, embed, model):\n",
        "    def predict(data):\n",
        "        preprocessed = (preprocess(datum) for datum in data)\n",
        "        embedded = embed(preprocessed)\n",
        "        result = model.predict(embedded)\n",
        "        return result\n",
        "    return predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz1p56sa8Co7"
      },
      "source": [
        "pipeline = make_pipeline(preprocess, use_lite_embed(), load_model())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8BRipIQ9NQJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e82b63e7-9d89-4f6c-f67e-88a76bd04f18"
      },
      "source": [
        "pipeline([\"a beautiful day\", \"you are a peice of shit\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}